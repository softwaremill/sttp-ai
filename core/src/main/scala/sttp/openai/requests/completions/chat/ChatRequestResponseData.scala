package sttp.openai.requests.completions.chat

import sttp.openai.json.SnakePickle
import sttp.openai.requests.completions.Usage

object ChatRequestResponseData {

  /** @param content
    *   The contents of the message.
    * @param refusal
    *   The refusal message generated by the model.
    * @param toolCalls
    *   The tool calls generated by the model, such as function calls.
    * @param role
    *   The role of the author of this message.
    * @param functionCall
    *   The name and arguments of a function that should be called, as generated by the model.
    * @param audio
    *   If the audio output modality is requested, this object contains data about the audio response from the model. Learn more.
    * @param id
    *   The identifier of the chat message.
    */
  case class Message(
      content: String,
      refusal: Option[String] = None,
      toolCalls: Seq[ToolCall] = Nil,
      role: Role,
      functionCall: Option[FunctionCall] = None,
      audio: Option[Audio] = None,
      id: String
  )

  object Message {
    implicit val messageR: SnakePickle.Reader[Message] = SnakePickle.macroR[Message]
  }

  /** An object representing a list of chat completion messages.
    *
    * @param `object`
    *   The type of this object. It is always set to "list".
    * @param data
    *   An array of chat completion message objects.
    * @param firstId
    *   The identifier of the first chat message in the data array.
    * @param lastId
    *   The identifier of the last chat message in the data array.
    * @param hasMore
    *   Indicates whether there are more chat messages available.
    */
  case class ListMessageResponse(
      `object`: String = "list",
      data: Seq[Message],
      firstId: String,
      lastId: String,
      hasMore: Boolean
  )

  object ListMessageResponse {
    implicit val listMessageR: SnakePickle.Reader[ListMessageResponse] = SnakePickle.macroR[ListMessageResponse]
  }

  /** Represents a choice in the chat completion.
    *
    * @param message
    *   The message associated with this choice.
    * @param finishReason
    *   The reason the model stopped generating tokens. This will be stop if the model hit a natural stop point or a provided stop sequence,
    *   length if the maximum number of tokens specified in the request was reached, content_filter if content was omitted due to a flag
    *   from our content filters, tool_calls if the model called a tool, or function_call (deprecated) if the model called a function.
    * @param index
    *   The index of this choice.
    * @param logprobs
    *   Log probability information for the choice.
    */
  case class Choices(
      message: Message,
      finishReason: String,
      index: Int,
      logprobs: Option[Logprobs] = None
  )

  object Choices {
    implicit val choicesR: SnakePickle.Reader[Choices] = SnakePickle.macroR[Choices]
  }

  /** @param content
    *   A list of message content tokens with log probability information.
    * @param refusal
    *   A list of message refusal tokens with log probability information.
    */
  case class Logprobs(
      content: Option[Seq[LogprobData]] = None,
      refusal: Option[Seq[LogprobData]] = None
  )

  object Logprobs {
    implicit val logprobsR: SnakePickle.Reader[Logprobs] = SnakePickle.macroR[Logprobs]
  }

  /** @param token
    *   The token.
    * @param logprob
    *   The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value -9999.0 is used to signify
    *   that the token is very unlikely.
    * @param bytes
    *   A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by
    *   multiple tokens and their byte representations must be combined to generate the correct text representation. Can be null if there is
    *   no bytes representation for the token.
    * @param topLogprobs
    *   List of the most likely tokens and their log probability, at this token position. In rare cases, there may be fewer than the number
    *   of requested top_logprobs returned.
    */
  case class LogprobData(
      token: String,
      logprob: Float,
      bytes: Option[Seq[Int]] = None,
      topLogprobs: Seq[TopLogprobs]
  )

  object LogprobData {
    implicit val contentR: SnakePickle.Reader[LogprobData] = SnakePickle.macroR[LogprobData]
  }

  /** @param token
    *   The token.
    * @param logprob
    *   The log probability of this token, if it is within the top 20 most likely tokens. Otherwise, the value -9999.0 is used to signify
    *   that the token is very unlikely.
    * @param bytes
    *   A list of integers representing the UTF-8 bytes representation of the token. Useful in instances where characters are represented by
    *   multiple tokens and their byte representations must be combined to generate the correct text representation. Can be null if there is
    *   no bytes representation for the token.
    */
  case class TopLogprobs(
      token: String,
      logprob: Float,
      bytes: Option[Seq[Int]] = None
  )

  object TopLogprobs {
    implicit val topLogprobsR: SnakePickle.Reader[TopLogprobs] = SnakePickle.macroR[TopLogprobs]
  }

  /** Represents the response of a chat completion.
    *
    * @param id
    *   A unique identifier for the chat completion.
    * @param choices
    *   A list of chat completion choices. Can be more than one if n is greater than 1.
    * @param created
    *   The Unix timestamp (in seconds) of when the chat completion was created.
    * @param model
    *   The model used for the chat completion.
    * @param `object`
    *   The object type, which is always chat.completion.
    * @param usage
    *   Usage statistics for the completion request.
    * @param systemFingerprint
    *   This fingerprint represents the backend configuration that the model runs with. Can be used in conjunction with the seed request
    *   parameter to understand when backend changes have been made that might impact determinism.
    * @param serviceTier
    *   The service tier used for processing the request.
    */
  case class ChatResponse(
      id: String,
      choices: Seq[Choices],
      created: Int,
      model: String,
      `object`: String,
      usage: Usage,
      systemFingerprint: Option[String] = None,
      serviceTier: Option[String] = None
  )

  object ChatResponse {
    implicit val chatResponseR: SnakePickle.Reader[ChatResponse] = SnakePickle.macroR[ChatResponse]
  }

  /** An object representing a list of chat completions.
    *
    * @param `object`
    *   The type of this object. It is always set to "list".
    * @param data
    *   An array of chat completion objects.
    * @param firstId
    *   The identifier of the first chat completion in the data array.
    * @param lastId
    *   The identifier of the last chat completion in the data array.
    * @param hasMore
    *   Indicates whether there are more chat completions available.
    */
  case class ListChatResponse(
      `object`: String = "list",
      data: Seq[ChatResponse],
      firstId: String,
      lastId: String,
      hasMore: Boolean
  )

  object ListChatResponse {
    implicit val listChatResponseR: SnakePickle.Reader[ListChatResponse] = SnakePickle.macroR[ListChatResponse]
  }

  case class DeleteChatCompletionResponse(
      `object`: String = "chat.completion.deleted",
      id: String,
      deleted: Boolean
  )

  object DeleteChatCompletionResponse {
    implicit val deleteChatCompletionResponseR: SnakePickle.Reader[DeleteChatCompletionResponse] =
      SnakePickle.macroR[DeleteChatCompletionResponse]
  }

}
